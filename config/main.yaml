pipeline:
  name: "TikTok Data Processing Pipeline"
  description: "Pipeline for processing TikTok data through various stages"
  
  # Pipeline configuration
  config:
    data_dir: "data/"
    output_dir: "data/output/"
    log_level: "INFO"
    
  # Pipeline stages, corresponding to each one of the Python pipeline layers 
  # inside of the src/ directory. Simply copy and paste if you want to add a new layer.
  stages:
    - name: "01_take_input_csv"
      module: "src.01_take_input_csv"
      function: "run"
      enabled: true
      config:
        input_file: "data/input.csv"
        output_file: "data/stage1_output.csv"
        # Output will be saved as: stage1_output_YYYYMMDD_HHMMSS.csv
        
    - name: "02_rule_based_filtering"
      module: "src.02_rule_based_filtering"
      function: "run"
      enabled: true
      config:
        input_file: "data/stage1_output.csv"
        rules_file: "src/rules.txt"
        output_file: "data/stage2_output.csv"
        # Output will be saved as: stage2_output_YYYYMMDD_HHMMSS.csv

    - name: "03_model_processing"
      module: "src.03_model_processing_v3"
      function: "run"
      enabled: true
      display_name: "Rigorous ML Pipeline (Ensemble Classification on Rule-Filtered Data)"
      config:
        input_file: "data/stage2_output.csv"
        output_file: "data/stage3_output.csv"
        model_config:
          # Rigorous ML configuration
          use_cached_models: true  # Load existing models if available
          ensemble_models:
            - logistic_regression
            - random_forest  
            - lightgbm
          text_representations:
            - tfidf_word
            - tfidf_char
            - hashing_vectorizer
            - svd_compression
            - lda_topics
            - sentence_embeddings
          validation:
            cv_folds: 5
            test_size: 0.2
            calibration_method: "isotonic"
        # Output: stage3_output.csv with ML predictions, probabilities, confidence scores + saved .pkl models
        
    - name: "04_relevance_check"
      module: "src.04_relevance_check"
      function: "run"
      enabled: true
      config:
        input_file: "data/stage3_output.csv"
        output_file: "data/stage4_output.csv"
        relevance_config:
          method: "cross_encoder"  # or alternatively, "sentence_similarity"
          threshold: 0.5
          batch_size: 16
          cross_encoder_model: "cross-encoder/ms-marco-MiniLM-L-6-v2"
          sentence_model: "all-MiniLM-L6-v2"
          use_cache: true
        # Output: stage4_output.csv with relevance scores and binary relevance flags
        
    - name: "05_evaluation"
      module: "src.05_evaluation"
      function: "run"
      enabled: true
      config:
        input_file: "data/input.csv"
        stage4_output: "data/stage4_output_*.csv"
        # Stage 5 will automatically find the most recent stage4_output file
        # Output: evaluation_metrics.json and evaluation_report.txt
        
  # Execution order and dependencies
  execution:
    parallel: false
    stop_on_error: true
    retry_failed: false
    max_retries: 3
